## Lab7 实验报告

### 练习1: 理解内核级信号量的实现和基于内核级信号量的哲学家就餐问题（不需要编码）

#### 给出内核级信号量的设计描述，并说其大致执行流程

信号量的组成分为可用值`value`和等待队列`wait_queue` (Line 8, `kern/sync/sem.h`)

```c
typedef struct {
    int value;
    wait_queue_t wait_queue;
} semaphore_t;
```

信号量的V操作 (释放资源) 的实现为`__up` (Line 16, `kern/sync/sem.c`)

```c
static __noinline void __up(semaphore_t *sem, uint32_t wait_state) {
    bool intr_flag;
    local_intr_save(intr_flag);
    {
        wait_t *wait;
        if ((wait = wait_queue_first(&(sem->wait_queue))) == NULL) {
            sem->value ++;
        }
        else {
            assert(wait->proc->wait_state == wait_state);
            wakeup_wait(&(sem->wait_queue), wait, wait_state, 1);
        }
    }
    local_intr_restore(intr_flag);
}
```

首先关中断，如果信号量对应的等待队列中没有进程在等待，把信号量可用值加1，然后开中断返回；否则，则调用`wakeup_wait`把其关联的进程唤醒，最后开中断返回。

信号量的P操作 (等待获取资源) 的实现为`__down` (Line 32, `kern/sync/sem.c`)

```c
static __noinline uint32_t __down(semaphore_t *sem, uint32_t wait_state) {
    bool intr_flag;
    local_intr_save(intr_flag);
    if (sem->value > 0) {
        sem->value --;
        local_intr_restore(intr_flag);
        return 0;
    }
    wait_t __wait, *wait = &__wait;
    wait_current_set(&(sem->wait_queue), wait, wait_state);
    local_intr_restore(intr_flag);

    schedule();

    local_intr_save(intr_flag);
    wait_current_del(&(sem->wait_queue), wait);
    local_intr_restore(intr_flag);

    if (wait->wakeup_flags != wait_state) {
        return wait->wakeup_flags;
    }
    return 0;
}
```

首先关中断，然后判断当前信号量的可用值是否大于0。如果是，则表明可以获得信号量，故让可用值减1，开中断返回即可；否则，即无法获得信号量时，需要将当前的进程加入到等待队列中，开中断，然后运行调度器选择另外一个进程执行。如果被V操作唤醒，即有其他进程释放该资源，则先关中断，把自身关联的wait从等待队列中删除，完成后开中断。

#### 给出给用户态进程/线程提供信号量机制的设计方案，并比较说明给内核级提供信号量机制的异同

算法思路与核心态完全一致，因为这个算法本身无所谓在什么状态下运行。

只要将相关方法封装成系统调用，即可实现在用户态的调用。

### 练习2: 完成内核级条件变量和基于内核级条件变量的哲学家就餐问题（需要编码）

#### 给出内核级条件变量的设计描述，并说其大致执行流程

条件变量`condvar`和管程`monitor`的定义如下 (Line 69, `kern/sync/monitor.h`)

```c
typedef struct condvar {
    semaphore_t sem;        // the sem semaphore is used to down the waiting proc, and the signaling proc should up the waiting proc
    int count;              // the number of waiters on condvar
    monitor_t * owner;      // the owner(monitor) of this condvar
} condvar_t;

typedef struct monitor {
    semaphore_t mutex;      // the mutex lock for going into the routines in monitor, should be initialized to 1
    semaphore_t next;       // the next semaphore is used to down the signaling proc itself, and the other OR wakeuped waiting proc should wake up the sleeped signaling proc.
    int next_count;         // the number of of sleeped signaling proc
    condvar_t *cv;          // the condvars in monitor
} monitor_t;
```

需要实现的是`cond_wait` (Line 52, `kern/sync/monitor.c`) 与 `cond_signal` (Line 26, `kern/sync/monitor.c`)。

```c
void
cond_wait (condvar_t *cvp) {
    cprintf...
    cvp->count++;
    if (cvp->owner->next_count > 0) {
        up(&(cvp->owner->next));
    } else {
        up(&(cvp->owner->mutex));
    }
    down(&(cvp->sem));
    cvp->count--;
    cprintf...
}
```

首先，等待此条件的休眠进程个数加1。接下来，

- 如果`cvp->owner->next_count > 0`，即有至少1个进程执行`cond_signal`函数且休眠了，这些进程形成一个链表。因此需要唤醒链表中的一个进程`cvp->owner->next`；

- 否则，即目前没有进程执行`cond_signal`函数且休眠了，那么需要唤醒的是由于互斥条件限制而无法进入管程的进程，即`cvp->owner->mutex`。

然后原来的进程休眠，再次被唤醒时，等待此条件的休眠进程个数减1。

```c
void
cond_signal (condvar_t *cvp) {
    cprintf...
    if (cvp->count > 0) {
       cvp->owner->next_count++;
       up(&(cvp->sem));
       down(&(cvp->owner->next));
       cvp->owner->next_count--;
    }
    cprintf...
}
```

首先判断等待此条件的休眠进程是否存在，如果不存在，就没有需要被唤醒的进程，直接退出；否则，当前有执行`cond_wait`而睡眠的进程`cvp->sem`，因此需要唤醒它。由于只允许一个进程在管程中执行，所以一旦进程唤醒了其他进程 (`cvp->sem`)，那么它自己就需要睡眠。故让等待进程个数加1，且让自己休眠。再次被唤醒时，等待进程个数减1。

#### 给出给用户态进程/线程提供条件变量机制的设计方案，并比较说明给内核级提供条件变量机制的异同

同理，用户态条件变量机制的设计原理同核心态。只要将相关方法封装成系统调用，即可实现在用户态的调用。
